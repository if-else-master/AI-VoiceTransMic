#!/usr/bin/env python3
"""
è¶…å¿«é€Ÿå³æ™‚èªéŸ³ç¿»è­¯ç³»çµ±
ç›®æ¨™ï¼šå»¶é² < 3ç§’
ç­–ç•¥ï¼šç°¡åŒ–æµç¨‹ï¼Œå¿«é€ŸéŸ¿æ‡‰
"""

import pyaudio
import wave
import threading
import time
import queue
import numpy as np
import torch
import scipy.io.wavfile
import tempfile
import os
import pygame
import google.generativeai as genai
from OpenVoice.checkpoints_v2.MeloTTS.melo.api import TTS
from OpenVoice.openvoice.api import ToneColorConverter
import tkinter as tk
from tkinter import ttk, messagebox, scrolledtext
from datetime import datetime

class UltraFastTranslator:
    def __init__(self):
        print("âš¡ åˆå§‹åŒ–è¶…å¿«é€Ÿç¿»è­¯ç³»çµ±...")
        
        # åŸºæœ¬é…ç½®
        self.device = "cpu"  # å¼·åˆ¶CPUé¿å…è¨­å‚™å•é¡Œ
        self.rate = 16000
        self.chunk = 256  # æ¥µå°chunk
        self.format = pyaudio.paInt16
        self.channels = 1
        
        # è¶…æ¿€é€²çš„å»¶é²å„ªåŒ–
        self.silence_threshold = 150
        self.silence_duration = 0.15  # æ¥µçŸ­éœéŸ³æª¢æ¸¬
        self.min_speech_duration = 0.05
        self.max_segment_duration = 1.5  # å¼·åˆ¶çŸ­èªéŸ³æ®µ
        
        # API
        self.gemini_api_key = None
        self.model = None
        
        # OpenVoice - åªè¼‰å…¥å¿…è¦æ¨¡å‹
        self.tone_color_converter = None
        self.en_tts_model = None  # åªè¼‰å…¥è‹±èªæ¨¡å‹
        self.target_se = None
        
        # èªè¨€
        self.source_language = 'zh'
        self.target_language = 'en'
        
        # æ§åˆ¶
        self.is_active = False
        self.should_stop = False
        
        # éšŠåˆ— - æ¥µå°ç·©è¡
        self.audio_queue = queue.Queue(maxsize=2)
        self.output_queue = queue.Queue(maxsize=2)
        
        # çµ±è¨ˆ
        self.latencies = []
        
        # GUIå¼•ç”¨
        self.gui = None
        
        # åˆå§‹åŒ–pygame
        pygame.mixer.init(frequency=22050, size=-16, channels=1, buffer=256)
        
        print("âœ… è¶…å¿«é€Ÿç¿»è­¯ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    
    def setup_api(self, api_key):
        """è¨­ç½®API"""
        try:
            self.gemini_api_key = api_key
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
            # é ç†±API
            self.model.generate_content("test")
            print("âœ… Gemini API é ç†±å®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ APIè¨­ç½®å¤±æ•—: {e}")
            return False
    
    def quick_load_models(self):
        """å¿«é€Ÿè¼‰å…¥é—œéµæ¨¡å‹"""
        try:
            print("ğŸš€ å¿«é€Ÿè¼‰å…¥æ¨¡å‹...")
            start_time = time.time()
            
            # 1. è¼‰å…¥ToneColorConverter
            ckpt_converter = 'OpenVoice/checkpoints_v2/converter'
            self.tone_color_converter = ToneColorConverter(
                f'{ckpt_converter}/config.json', 
                device=self.device
            )
            self.tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')
            print("âœ… ToneColorConverterè¼‰å…¥å®Œæˆ")
            
            # 2. åªè¼‰å…¥è‹±èªTTSæ¨¡å‹ï¼ˆæœ€å¿«ï¼‰
            self.en_tts_model = TTS(language='EN_NEWEST', device=self.device)
            print("âœ… è‹±èªTTSæ¨¡å‹è¼‰å…¥å®Œæˆ")
            
            # 3. è¼‰å…¥ç¾æœ‰èªéŸ³ç‰¹å¾µ
            import glob
            voice_files = glob.glob("cloned_voices/*.wav")
            if voice_files:
                self.target_se = self.tone_color_converter.extract_se(voice_files[0])
                print("âœ… èªéŸ³ç‰¹å¾µè¼‰å…¥å®Œæˆ")
            
            load_time = time.time() - start_time
            print(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œè€—æ™‚: {load_time:.2f}ç§’")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def quick_clone_voice(self, duration=2):
        """å¿«é€ŸèªéŸ³å…‹éš†"""
        try:
            print("ğŸ¤ å¿«é€ŸèªéŸ³éŒ„è£½ï¼ˆ2ç§’ï¼‰...")
            
            if not os.path.exists("cloned_voices"):
                os.makedirs("cloned_voices")
            
            # éŒ„éŸ³
            audio = pyaudio.PyAudio()
            stream = audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )
            
            frames = []
            start_time = time.time()
            
            print("ğŸ™ï¸ è«‹èªªè©±...")
            while time.time() - start_time < duration:
                data = stream.read(self.chunk)
                frames.append(data)
            
            stream.stop_stream()
            stream.close()
            audio.terminate()
            
            # ä¿å­˜
            clone_file = f"cloned_voices/fast_clone_{int(time.time())}.wav"
            wf = wave.open(clone_file, 'wb')
            wf.setnchannels(self.channels)
            wf.setsampwidth(pyaudio.PyAudio().get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(frames))
            wf.close()
            
            # å¿«é€Ÿæå–ç‰¹å¾µ
            self.target_se = self.tone_color_converter.extract_se(clone_file)
            print("âœ… å¿«é€ŸèªéŸ³å…‹éš†å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ èªéŸ³å…‹éš†å¤±æ•—: {e}")
            return False
    
    def start_ultra_fast_translation(self):
        """å•Ÿå‹•è¶…å¿«é€Ÿç¿»è­¯"""
        if not self.model or not self.tone_color_converter or self.target_se is None:
            print("âŒ ç³»çµ±æœªæº–å‚™å®Œæˆ")
            return False
        
        self.is_active = True
        self.should_stop = False
        self.latencies = []
        
        # æ¸…ç©ºéšŠåˆ—
        while not self.audio_queue.empty():
            try: self.audio_queue.get_nowait()
            except: break
        while not self.output_queue.empty():
            try: self.output_queue.get_nowait()
            except: break
        
        # å•Ÿå‹•ç·šç¨‹
        threads = [
            threading.Thread(target=self._ultra_fast_capture, daemon=True),
            threading.Thread(target=self._ultra_fast_process, daemon=True),
            threading.Thread(target=self._ultra_fast_play, daemon=True),
        ]
        
        for t in threads:
            t.start()
        
        self.threads = threads
        print("âš¡ è¶…å¿«é€Ÿç¿»è­¯å•Ÿå‹• - ç›®æ¨™ < 3ç§’")
        return True
    
    def stop_translation(self):
        """åœæ­¢ç¿»è­¯"""
        self.should_stop = True
        self.is_active = False
        
        if hasattr(self, 'threads'):
            for t in self.threads:
                t.join(timeout=1)
        
        if self.latencies:
            avg_latency = sum(self.latencies) / len(self.latencies)
            print(f"ğŸ“Š å¹³å‡å»¶é²: {avg_latency:.2f}ç§’")
        
        print("â¹ï¸ ç¿»è­¯å·²åœæ­¢")
    
    def _ultra_fast_capture(self):
        """è¶…å¿«éŸ³é »æ•ç²"""
        audio = pyaudio.PyAudio()
        stream = audio.open(
            format=self.format,
            channels=self.channels,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunk
        )
        
        current_segment = []
        last_speech_time = 0
        is_speech = False
        segment_start = time.time()
        
        print("ğŸ¤ è¶…å¿«éŸ³é »æ•ç²å•Ÿå‹•")
        
        while self.is_active:
            try:
                data = stream.read(self.chunk, exception_on_overflow=False)
                audio_np = np.frombuffer(data, dtype=np.int16)
                rms = np.sqrt(np.mean(audio_np.astype(np.float64)**2))
                current_time = time.time()
                
                if rms > self.silence_threshold:
                    if not is_speech:
                        is_speech = True
                        segment_start = current_time
                        if self.gui:
                            self.gui.update_status("ğŸ¤ èªéŸ³...")
                    
                    current_segment.extend(audio_np)
                    last_speech_time = current_time
                
                else:
                    if is_speech:
                        silence_time = current_time - last_speech_time
                        segment_duration = current_time - segment_start
                        
                        # æ›´æ¿€é€²çš„åˆ†å‰²æ¢ä»¶
                        should_process = (
                            silence_time >= self.silence_duration or 
                            segment_duration >= self.max_segment_duration
                        )
                        
                        if should_process and len(current_segment) > int(self.rate * self.min_speech_duration):
                            audio_data = np.array(current_segment, dtype=np.int16)
                            try:
                                self.audio_queue.put_nowait((audio_data, current_time))
                                if self.gui:
                                    self.gui.update_status("ğŸ”„ è™•ç†ä¸­...")
                            except queue.Full:
                                pass  # ä¸Ÿæ£„ä»¥é¿å…å»¶é²ç´¯ç©
                            
                            current_segment = []
                            is_speech = False
                
            except Exception as e:
                print(f"âŒ æ•ç²éŒ¯èª¤: {e}")
                break
        
        stream.stop_stream()
        stream.close()
        audio.terminate()
        print("ğŸ¤ éŸ³é »æ•ç²åœæ­¢")
    
    def _ultra_fast_process(self):
        """è¶…å¿«è™•ç†æµç¨‹"""
        print("âš¡ è¶…å¿«è™•ç†ç·šç¨‹å•Ÿå‹•")
        
        while self.is_active or not self.audio_queue.empty():
            try:
                audio_data, capture_time = self.audio_queue.get(timeout=0.5)
                process_start = time.time()
                
                # 1. ä¿å­˜éŸ³é »
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
                scipy.io.wavfile.write(temp_file.name, self.rate, audio_data)
                
                # 2. ä¸Šå‚³ä¸¦è™•ç†ï¼ˆåˆä½µæ“ä½œï¼‰
                audio_file = genai.upload_file(path=temp_file.name)
                
                # 3. ä¸€æ¬¡æ€§è½‰éŒ„+ç¿»è­¯
                prompt = f"""è™•ç†é€™æ®µä¸­æ–‡èªéŸ³ï¼ŒåŸ·è¡Œï¼š
1. è½‰éŒ„ç‚ºä¸­æ–‡æ–‡å­—
2. ç¿»è­¯ç‚ºè‹±æ–‡
å›å‚³æ ¼å¼ï¼šç¿»è­¯çµæœï¼ˆä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ï¼‰"""
                
                response = self.model.generate_content([audio_file, prompt])
                translated_text = response.text.strip()
                
                # æ¸…ç†
                genai.delete_file(audio_file.name)
                os.unlink(temp_file.name)
                
                # 4. å¿«é€ŸèªéŸ³åˆæˆ
                output_file = self._ultra_fast_synthesize(translated_text)
                
                if output_file:
                    total_latency = time.time() - capture_time
                    self.latencies.append(total_latency)
                    
                    print(f"âš¡ ç¿»è­¯: {translated_text}")
                    print(f"â±ï¸ ç¸½å»¶é²: {total_latency:.2f}ç§’")
                    
                    if self.gui:
                        self.gui.add_translation(translated_text, total_latency)
                    
                    try:
                        self.output_queue.put_nowait((output_file, total_latency))
                    except queue.Full:
                        try:
                            os.unlink(output_file)
                        except:
                            pass
                
                self.audio_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ è™•ç†éŒ¯èª¤: {e}")
        
        print("âš¡ è™•ç†ç·šç¨‹åœæ­¢")
    
    def _ultra_fast_synthesize(self, text):
        """è¶…å¿«èªéŸ³åˆæˆ"""
        try:
            if not text.strip() or len(text) > 200:  # é™åˆ¶é•·åº¦
                return None
            
            # ä½¿ç”¨é è¼‰å…¥çš„è‹±èªTTSæ¨¡å‹
            temp_src = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            
            speaker_ids = self.en_tts_model.hps.data.spk2id
            speaker_key = list(speaker_ids.keys())[0]
            speaker_id = speaker_ids[speaker_key]
            
            # å¿«é€ŸTTS
            self.en_tts_model.tts_to_file(
                text, speaker_id, temp_src.name, 
                speed=1.2,  # ç¨å¿«èªé€Ÿ
                quiet=True  # éœé»˜æ¨¡å¼
            )
            
            # å¿«é€ŸèªéŸ³è½‰æ›
            speaker_key_formatted = speaker_key.lower().replace('_', '-')
            source_se_path = f'OpenVoice/checkpoints_v2/base_speakers/ses/{speaker_key_formatted}.pth'
            
            if os.path.exists(source_se_path):
                source_se = torch.load(source_se_path, map_location=self.device)
                
                output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
                self.tone_color_converter.convert(
                    audio_src_path=temp_src.name,
                    src_se=source_se,
                    tgt_se=self.target_se,
                    output_path=output_file.name,
                    message="@Fast"
                )
                
                os.unlink(temp_src.name)
                return output_file.name
            else:
                return temp_src.name  # è¿”å›åŸå§‹TTSçµæœ
                
        except Exception as e:
            print(f"âŒ åˆæˆéŒ¯èª¤: {e}")
            return None
    
    def _ultra_fast_play(self):
        """è¶…å¿«æ’­æ”¾"""
        print("ğŸ”Š è¶…å¿«æ’­æ”¾ç·šç¨‹å•Ÿå‹•")
        
        while self.is_active or not self.output_queue.empty():
            try:
                audio_file, latency = self.output_queue.get(timeout=0.5)
                
                # æ’­æ”¾
                pygame.mixer.music.load(audio_file)
                pygame.mixer.music.play()
                
                # ä¸ç­‰å¾…æ’­æ”¾å®Œæˆï¼Œç«‹å³è™•ç†ä¸‹ä¸€å€‹
                # é€™æ¨£å¯ä»¥é‡ç–Šæ’­æ”¾ï¼Œé€²ä¸€æ­¥æ¸›å°‘æ„ŸçŸ¥å»¶é²
                
                print(f"ğŸ”Š æ’­æ”¾é–‹å§‹ï¼Œå»¶é²: {latency:.2f}ç§’")
                
                # æ¸…ç†æ–‡ä»¶
                def cleanup():
                    time.sleep(2)  # ç­‰å¾…æ’­æ”¾å®Œæˆ
                    try:
                        os.unlink(audio_file)
                    except:
                        pass
                
                threading.Thread(target=cleanup, daemon=True).start()
                
                self.output_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ æ’­æ”¾éŒ¯èª¤: {e}")
        
        print("ğŸ”Š æ’­æ”¾ç·šç¨‹åœæ­¢")

class UltraFastGUI:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("âš¡ è¶…å¿«é€Ÿå³æ™‚ç¿»è­¯ç³»çµ± (ç›®æ¨™ < 3ç§’)")
        self.root.geometry("800x600")
        self.root.configure(bg='#000000')
        
        self.translator = UltraFastTranslator()
        self.translator.gui = self
        
        self.is_active = False
        self.create_widgets()
    
    def create_widgets(self):
        # æ¨™é¡Œ
        title_frame = tk.Frame(self.root, bg='#000000')
        title_frame.pack(pady=10)
        
        tk.Label(title_frame, text="âš¡ è¶…å¿«é€Ÿå³æ™‚ç¿»è­¯", 
                font=('Arial', 24, 'bold'), 
                bg='#000000', fg='#00ff00').pack()
        
        tk.Label(title_frame, text="ç›®æ¨™å»¶é² < 3ç§’", 
                font=('Arial', 14), 
                bg='#000000', fg='#ffff00').pack()
        
        # APIè¨­ç½®
        api_frame = tk.Frame(self.root, bg='#000000')
        api_frame.pack(pady=10)
        
        tk.Label(api_frame, text="Gemini API Key:", 
                bg='#000000', fg='white', font=('Arial', 12)).pack(side='left')
        
        self.api_entry = tk.Entry(api_frame, width=40, show='*', font=('Arial', 12))
        self.api_entry.pack(side='left', padx=10)
        
        tk.Button(api_frame, text="è¨­ç½®", command=self.setup_api,
                 bg='#333333', fg='white', font=('Arial', 12)).pack(side='left')
        
        # æ§åˆ¶æŒ‰éˆ•
        control_frame = tk.Frame(self.root, bg='#000000')
        control_frame.pack(pady=20)
        
        tk.Button(control_frame, text="å¿«é€Ÿè¼‰å…¥æ¨¡å‹", command=self.load_models,
                 bg='#333333', fg='white', font=('Arial', 14)).pack(side='left', padx=10)
        
        tk.Button(control_frame, text="å¿«é€ŸéŒ„éŸ³", command=self.clone_voice,
                 bg='#333333', fg='white', font=('Arial', 14)).pack(side='left', padx=10)
        
        self.start_button = tk.Button(control_frame, text="é–‹å§‹è¶…å¿«ç¿»è­¯", command=self.toggle_translation,
                                     bg='#006600', fg='white', font=('Arial', 16, 'bold'))
        self.start_button.pack(side='left', padx=10)
        
        # ç‹€æ…‹
        self.status_label = tk.Label(self.root, text="ç³»çµ±å°±ç·’", 
                                    bg='#000000', fg='#00ff00', font=('Arial', 14))
        self.status_label.pack(pady=10)
        
        # å»¶é²é¡¯ç¤º
        self.latency_label = tk.Label(self.root, text="å»¶é²: --", 
                                     bg='#000000', fg='#ffff00', font=('Arial', 16, 'bold'))
        self.latency_label.pack()
        
        # ç¿»è­¯çµæœ
        tk.Label(self.root, text="ç¿»è­¯çµæœ:", bg='#000000', fg='white', 
                font=('Arial', 14, 'bold')).pack(anchor='w', padx=20, pady=(20,5))
        
        self.result_text = scrolledtext.ScrolledText(self.root, height=15, 
                                                    bg='#111111', fg='#00ff00',
                                                    font=('Arial', 12))
        self.result_text.pack(fill='both', expand=True, padx=20, pady=10)
    
    def setup_api(self):
        api_key = self.api_entry.get().strip()
        if not api_key:
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥API Key")
            return
        
        if self.translator.setup_api(api_key):
            messagebox.showinfo("æˆåŠŸ", "APIè¨­ç½®æˆåŠŸ")
            self.update_status("APIå·²è¨­ç½®")
        else:
            messagebox.showerror("éŒ¯èª¤", "APIè¨­ç½®å¤±æ•—")
    
    def load_models(self):
        self.update_status("å¿«é€Ÿè¼‰å…¥æ¨¡å‹ä¸­...")
        
        def load():
            success = self.translator.quick_load_models()
            self.root.after(0, lambda: self.model_loaded(success))
        
        threading.Thread(target=load, daemon=True).start()
    
    def model_loaded(self, success):
        if success:
            self.update_status("æ¨¡å‹è¼‰å…¥å®Œæˆ")
            messagebox.showinfo("æˆåŠŸ", "æ¨¡å‹å¿«é€Ÿè¼‰å…¥å®Œæˆ")
        else:
            messagebox.showerror("éŒ¯èª¤", "æ¨¡å‹è¼‰å…¥å¤±æ•—")
    
    def clone_voice(self):
        if not self.translator.tone_color_converter:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¼‰å…¥æ¨¡å‹")
            return
        
        self.update_status("å¿«é€ŸéŒ„éŸ³ä¸­...")
        
        def clone():
            success = self.translator.quick_clone_voice()
            self.root.after(0, lambda: self.voice_cloned(success))
        
        threading.Thread(target=clone, daemon=True).start()
    
    def voice_cloned(self, success):
        if success:
            self.update_status("èªéŸ³éŒ„è£½å®Œæˆ")
            messagebox.showinfo("æˆåŠŸ", "å¿«é€ŸèªéŸ³å…‹éš†å®Œæˆ")
        else:
            messagebox.showerror("éŒ¯èª¤", "èªéŸ³å…‹éš†å¤±æ•—")
    
    def toggle_translation(self):
        if not self.is_active:
            if not self.translator.model:
                messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¨­ç½®API")
                return
            if not self.translator.tone_color_converter:
                messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¼‰å…¥æ¨¡å‹")
                return
            if self.translator.target_se is None:
                messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆéŒ„è£½èªéŸ³")
                return
            
            self.result_text.delete(1.0, tk.END)
            
            if self.translator.start_ultra_fast_translation():
                self.is_active = True
                self.start_button.config(text="åœæ­¢ç¿»è­¯", bg='#cc0000')
                self.update_status("âš¡ è¶…å¿«ç¿»è­¯é‹è¡Œä¸­")
        else:
            self.translator.stop_translation()
            self.is_active = False
            self.start_button.config(text="é–‹å§‹è¶…å¿«ç¿»è­¯", bg='#006600')
            self.update_status("ç¿»è­¯å·²åœæ­¢")
    
    def update_status(self, message):
        self.status_label.config(text=message)
        self.root.update_idletasks()
    
    def add_translation(self, text, latency):
        timestamp = datetime.now().strftime("%H:%M:%S")
        color = '#00ff00' if latency < 3.0 else '#ffff00' if latency < 5.0 else '#ff0000'
        
        self.result_text.insert(tk.END, f"[{timestamp}] {text}\n")
        self.result_text.see(tk.END)
        
        self.latency_label.config(text=f"å»¶é²: {latency:.1f}ç§’", fg=color)
    
    def run(self):
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        self.root.mainloop()
    
    def on_closing(self):
        if self.is_active:
            self.translator.stop_translation()
        self.root.destroy()

if __name__ == "__main__":
    app = UltraFastGUI()
    app.run()